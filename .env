# ezlocalai Configuration - keeping it "ez"
# VRAM is auto-detected, context is dynamic, GPU layers are auto-calibrated

MAIN_GPU=0
NGROK_TOKEN=
EZLOCALAI_API_KEY=
EZLOCALAI_URL=http://localhost:8091

# Models (comma-separated) - context and GPU layers are automatic
DEFAULT_MODEL=unsloth/Qwen3-VL-4B-Instruct-GGUF,unsloth/Qwen3-Coder-30B-A3B-Instruct-GGUF

# Image generation (set IMG_MODEL to enable, leave empty to disable)
IMG_MODEL=

# Speech-to-text model
WHISPER_MODEL=base

# Queue settings
MAX_CONCURRENT_REQUESTS=2
MAX_QUEUE_SIZE=100
REQUEST_TIMEOUT=300
